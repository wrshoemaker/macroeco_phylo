import sys
import config
import numpy
import random
from collections import Counter
import diversity_utils
import dbd_utils
import pickle
import scipy.stats as stats
import itertools
import matplotlib.pyplot as plt


taxon_path = config.data_directory + "neutral_s_by_s_rarefied/taxon/%s.pickle"
phylo_path = config.data_directory + "neutral_s_by_s_rarefied/phylo/%s.pickle"

#richness_dbd_neutral_dict_path = config.data_directory + "richness_dbd_neutral_dict.pickle"
richness_dbd_neutral_dict_path = config.data_directory + "figure-3-figure-supplement-3-source-data.pickle"


environments_to_keep = diversity_utils.environments_to_keep
rarefied = False


random.seed(123456789)
numpy.random.seed(123456789)

def subsample_sad(sad, n_subsample=5000):

    all_individuals = []
    idx_all = list(range(len(sad)))
    #for idx, i in enumerate(idx_all):
    for sad_i_idx, sad_i in enumerate(sad):

        if sad_i>0:       
            all_individuals.extend( [sad_i_idx]* int(sad_i) )

    subsample_individuals = random.sample(all_individuals, n_subsample)
    species_counts = dict(Counter(subsample_individuals))
    # add missing species
    subsampled_sad = []
    for idx in idx_all:
        if idx not in species_counts:
            subsampled_sad.append(0)
        else:
            subsampled_sad.append(species_counts[idx])
    return subsampled_sad




def make_rarefied_sads_dict():

    # Neutral SADs generated by running generate_neutral_s_by_s.R

    for environment in environments_to_keep:

        # Observed taxonomic
        pres_abs_dict = dbd_utils.load_sad_annotated_no_subsampling_taxon_dict(environment, rarefied = False)
        taxa = numpy.asarray(list(pres_abs_dict['taxa'].keys()))
        sys.stderr.write("Getting taxonomic site-by-species matrix...\n")
        s_by_s = numpy.asarray([pres_abs_dict['taxa'][t]['abundance'] for t in taxa])
        subsampled_sad_observed_all_taxon = [subsample_sad(sad) for sad in s_by_s.T]


        # Observed phylogenetic
        pres_abs_dict = dbd_utils.load_sad_annotated_no_subsampling_phylo_dict(environment, rarefied = False)
        taxa = numpy.asarray(list(pres_abs_dict['taxa'].keys()))
        sys.stderr.write("Getting phylogenetic site-by-species matrix...\n")
        s_by_s = numpy.asarray([pres_abs_dict['taxa'][t]['abundance'] for t in taxa])
        subsampled_sad_observed_all_phylo = [subsample_sad(sad) for sad in s_by_s.T]

        # Neutral simulated taxonomic
        neutral_path_taxon = '%sneutral_s_by_s/taxon/%s.csv' % (config.data_directory, '_'.join(environment.split(' ')[:-1]))
        s_by_s_neutral_taxon = numpy.loadtxt(neutral_path_taxon, delimiter=" ", dtype=int)
        subsampled_sad_observed_neutral_all_taxon = [subsample_sad(sad) for sad in s_by_s_neutral_taxon]
        

        # Neutral simulated phylogenetic
        neutral_path_phylo = '%sneutral_s_by_s/phylo/%s.csv' % (config.data_directory, '_'.join(environment.split(' ')[:-1]))
        s_by_s_neutral_phylo = numpy.loadtxt(neutral_path_phylo, delimiter=" ", dtype=int)
        subsampled_sad_observed_neutral_all_phylo = [subsample_sad(sad) for sad in s_by_s_neutral_phylo]
        
        rarefied_taxon_dict = {}
        rarefied_phylo_dict = {}

        rarefied_taxon_dict['observed'] = subsampled_sad_observed_all_taxon
        rarefied_taxon_dict['neutral'] = subsampled_sad_observed_neutral_all_taxon
        
        rarefied_phylo_dict['observed'] = subsampled_sad_observed_all_phylo
        rarefied_phylo_dict['neutral'] = subsampled_sad_observed_neutral_all_phylo

        # save dictionaries
        taxon_path_ = taxon_path % diversity_utils.get_environment_label(environment)
        phylo_path_ = phylo_path % diversity_utils.get_environment_label(environment)

        sys.stderr.write("Saving taxon dictionary...\n")
        with open(taxon_path_, 'wb') as handle:
            pickle.dump(rarefied_taxon_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)

        sys.stderr.write("Saving phylo dictionary...\n")
        with open(phylo_path_, 'wb') as handle:
            pickle.dump(rarefied_phylo_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)




def make_neutral_dbd_slope_dict():

    coarse_grained_tree_dict = dbd_utils.make_coarse_grained_tree_no_subsampling_all_dict()

    dbd_dict = {}

    for environment_idx, environment in enumerate(diversity_utils.environments_to_keep):

        taxon_path_ = taxon_path % diversity_utils.get_environment_label(environment)
        phylo_path_ = phylo_path % diversity_utils.get_environment_label(environment)

        sys.stderr.write("Loading taxon dict for %s...\n" % environment)
        sad_annotated_dict = dbd_utils.load_sad_annotated_no_subsampling_taxon_dict(environment, rarefied=False)
        taxa = numpy.asarray(list(sad_annotated_dict['taxa'].keys()))
        #s_by_s = numpy.asarray([sad_annotated_dict['taxa'][t]['abundance'] for t in taxa])
        
        # load taxon neutral dict
        with open(taxon_path_, 'rb') as handle:
            taxon_dict = pickle.load(handle)

        s_by_s = numpy.asarray(taxon_dict['observed'])
        s_by_s = s_by_s.T

        s_by_s_neutral = numpy.asarray(taxon_dict['neutral'])
        s_by_s_neutral = s_by_s_neutral.T

        dbd_dict[environment] = {}
        dbd_dict[environment]['taxon'] = {}
        dbd_dict[environment]['phylo'] = {}

        dbd_slope_dict = {}
        for coarse_rank_idx, coarse_rank in enumerate(diversity_utils.taxa_ranks):

            sys.stderr.write("Starting %s level analysis...\n" % coarse_rank)
            dbd_slope_dict[coarse_rank] = {}

            if coarse_rank == 'genus':
                fine_rank = 'asv'
                all_fine = numpy.copy(taxa).tolist()
            else:
                fine_rank = diversity_utils.taxa_ranks[coarse_rank_idx-1]
                all_fine = list([sad_annotated_dict['taxa'][t][fine_rank] for t in taxa])

            sys.stderr.write("Estimating %s level DBD slope...\n" % coarse_rank)

            set_fine = list(set(all_fine))
            all_fine = numpy.asarray(all_fine)
            set_fine =  numpy.asarray(set_fine)

            fine_coarse_dict = {}
            for t in taxa:

                if fine_rank == 'asv':
                    fine_coarse_dict[t] = sad_annotated_dict['taxa'][t][coarse_rank]

                else:
                    fine_rank_t = sad_annotated_dict['taxa'][t][fine_rank]
                    if fine_rank_t not in fine_coarse_dict:
                        fine_coarse_dict[fine_rank_t] = sad_annotated_dict['taxa'][t][coarse_rank]


            if fine_rank == 'asv':
                s_by_s_fine = numpy.copy(s_by_s)
                s_by_s_neutral_fine = numpy.copy(s_by_s_neutral)
                all_coarse = []
                for fine in set_fine:
                    all_coarse.append(fine_coarse_dict[fine])
                all_coarse = numpy.asarray(all_coarse)


            else:
                sad_fine_all = []
                sad_fine_neutral_all = []
                all_coarse = []
                for fine in set_fine:
                    taxa_in_fine = []
                    for t in taxa:

                        if sad_annotated_dict['taxa'][t][fine_rank] == fine:
                            taxa_in_fine.append(t)

                    # numpy.where() is a major bottleneck
                    g_taxa_idx = numpy.asarray([numpy.where(taxa == taxa_in_fine_i)[0][0] for taxa_in_fine_i in taxa_in_fine])
                    sad_fine_all.append(s_by_s[g_taxa_idx,:].sum(axis=0))
                    sad_fine_neutral_all.append(s_by_s_neutral[g_taxa_idx,:].sum(axis=0))
                    all_coarse.append(fine_coarse_dict[fine])

                all_coarse = numpy.asarray(all_coarse)
                s_by_s_fine = numpy.stack(sad_fine_all, axis=0)
                s_by_s_neutral_fine = numpy.stack(sad_fine_neutral_all, axis=0)


            # remove sites where there are no observations
            s_by_s_fine = s_by_s_fine[:,~(numpy.all(s_by_s_fine == 0, axis=0))]
            s_by_s_neutral_fine = s_by_s_neutral_fine[:,~(numpy.all(s_by_s_neutral_fine == 0, axis=0))]

            # sort s_by_s_fine
            # so we can use cumsum
            set_coarse = list(set(all_coarse))
            idx_to_sort = []
            counts_coarse = []
            for coarse in set_coarse:
                idx_coarse_i = numpy.where(all_coarse==coarse)[0].tolist()
                counts_coarse.append(len(idx_coarse_i))
                idx_to_sort.append(idx_coarse_i)


            idx_to_sort_flat =  list(itertools.chain(*idx_to_sort))
            idx_to_sort_flat = numpy.asarray(idx_to_sort_flat)
            s_by_s_fine = s_by_s_fine[idx_to_sort_flat,:]
            s_by_s_neutral_fine = s_by_s_neutral_fine[idx_to_sort_flat,:]

            # coarse-grain
            coarse_idx = numpy.append([0], numpy.cumsum(counts_coarse))[:-1]
            s_by_s_coarse = numpy.add.reduceat(s_by_s_fine, coarse_idx, axis=0)       
            s_by_s_neutral_coarse = numpy.add.reduceat(s_by_s_neutral_fine, coarse_idx, axis=0)       

            # predict diversity and richnesss
            observed_mean_richness =  numpy.mean(numpy.apply_along_axis(diversity_utils.calculate_richness, 0, s_by_s_coarse))
            predicted_mean_richness =  numpy.mean(numpy.apply_along_axis(diversity_utils.calculate_richness, 0, s_by_s_neutral_coarse))

            dbd_dict[environment]['taxon'][coarse_rank] = {}
            dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'] = {}

            dbd_dict[environment]['taxon'][coarse_rank]['observed_mean_richness'] = observed_mean_richness
            dbd_dict[environment]['taxon'][coarse_rank]['predicted_mean_richness'] = predicted_mean_richness

            slope_all = []
            slope_neutral_all = []

            for focal_coarse_idx, focal_coarse in enumerate(set_coarse):

                # ignore coarse-grained taxa with less than five fine-grained taxa
                if counts_coarse[focal_coarse_idx] < 5:
                    continue

                # all the fine-scale indices for the focal
                focal_s_by_s_coarse_idx = numpy.asarray(idx_to_sort[focal_coarse_idx])
                focal_fine_s_by_s = s_by_s_fine[focal_s_by_s_coarse_idx,:]
                nonfocal_s_by_s_coarse = numpy.delete(s_by_s_coarse, focal_coarse_idx, axis=0)

                focal_fine_s_by_s_neutral = s_by_s_neutral_fine[focal_s_by_s_coarse_idx,:]
                nonfocal_s_by_s_coarse_neutral = numpy.delete(s_by_s_neutral_coarse, focal_coarse_idx, axis=0)

                measure_coarse = numpy.sum(nonfocal_s_by_s_coarse > 0, axis=0)
                measure_fine = numpy.sum(focal_fine_s_by_s > 0, axis=0)

                measure_coarse_neutral = numpy.sum(nonfocal_s_by_s_coarse_neutral > 0, axis=0)
                measure_fine_neutral = numpy.sum(focal_fine_s_by_s_neutral > 0, axis=0)


                if len(measure_fine) < 5:
                    continue

                slope, intercept, r_value, p_value, std_err = stats.linregress(measure_coarse, measure_fine)
                slope_neutral, intercept_neutral, r_value_neutral, p_value_neutral, std_err_neutral = stats.linregress(measure_coarse_neutral, measure_fine_neutral)

                slope_all.append(slope)
                slope_neutral_all.append(slope_neutral)

                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse] = {}
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['measure_coarse'] = measure_coarse.tolist()
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['measure_fine'] = measure_fine.tolist()
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['measure_coarse_predicted'] = nonfocal_s_by_s_coarse_neutral.tolist()
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['measure_fine_predicted'] = focal_fine_s_by_s_neutral.tolist()
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['slope'] = slope
                #dbd_dict[environment]['taxon'][coarse_rank]['focal_coarse'][focal_coarse]['slope_slm'] = slope_neutral

        

            slope_all = numpy.asarray(slope_all)
            slope_neutral_all = numpy.asarray(slope_neutral_all)
    
            #idx_to_keep = ~(numpy.isnan(slope_all) | numpy.isnan(slope_neutral_all) )  
            idx_to_keep = numpy.isfinite(slope_all) & numpy.isfinite(slope_neutral_all) & (numpy.absolute(slope_all)>0) 

            if sum(idx_to_keep) < 3:
                continue

            slope_all = slope_all[idx_to_keep]
            slope_neutral_all = slope_neutral_all[idx_to_keep]

            mean_slope_all = numpy.mean(slope_all)
            mean_slope_neutral_all = numpy.mean(slope_neutral_all)
  
            # error
            mean_error_slope_neutral = numpy.mean(numpy.absolute( slope_neutral_all - slope_all) / numpy.absolute(slope_all))


            dbd_dict[environment]['taxon'][coarse_rank]['slope_all'] = slope_all.tolist()
            dbd_dict[environment]['taxon'][coarse_rank]['slope_neutral_all'] = slope_neutral_all.tolist()
            dbd_dict[environment]['taxon'][coarse_rank]['mean_slope'] = mean_slope_all
            dbd_dict[environment]['taxon'][coarse_rank]['mean_slope_neutral'] = mean_slope_neutral_all
            dbd_dict[environment]['taxon'][coarse_rank]['mean_error_slope_neutral'] = mean_error_slope_neutral


        # phylogenetic DBD
        sys.stderr.write("Subsetting samples for %s...\n" % environment)
        coarse_grained_tree_dict_env = coarse_grained_tree_dict[environment]
        sad_annotated_dict = dbd_utils.load_sad_annotated_no_subsampling_phylo_dict(environment, rarefied = False)
        samples = sad_annotated_dict['samples']

        taxa = numpy.asarray(list(sad_annotated_dict['taxa'].keys()))
        s_by_s = numpy.asarray([sad_annotated_dict['taxa'][t]['abundance'] for t in taxa])

        distances = list(coarse_grained_tree_dict_env.keys())
        distances.sort()

        distances = numpy.asarray(distances)

        # load phylo neutral dict
        with open(phylo_path_, 'rb') as handle:
            phylo_dict = pickle.load(handle)

        s_by_s = numpy.asarray(phylo_dict['observed'])
        s_by_s = s_by_s.T

        s_by_s_neutral = numpy.asarray(phylo_dict['neutral'])
        s_by_s_neutral = s_by_s_neutral.T

        for distance_idx in range(len(distances) - 1):
            
            fine_distance = distances[distance_idx]
            coarse_distance = distances[distance_idx + 1]

            sys.stderr.write("Phylo distance = %s \n" % round(coarse_distance, 7))

            fine_grained_list = coarse_grained_tree_dict_env[fine_distance]
            coarse_grained_list = coarse_grained_tree_dict_env[coarse_distance]

            coarse_grained_idx_all = [numpy.asarray([numpy.where(taxa==i)[0][0] for i in coarse_grained_list_i]) for coarse_grained_list_i in coarse_grained_list]
            fine_grained_idx_all = [numpy.asarray([numpy.where(taxa==i)[0][0] for i in fine_grained_list_i]) for fine_grained_list_i in fine_grained_list]

            # coarse grain s-by-s for all clades
            s_by_s_coarse = numpy.stack([numpy.sum(s_by_s[coarse_grained_idx,:], axis=0) for coarse_grained_idx in coarse_grained_idx_all], axis=0)
            s_by_s_fine = numpy.stack([numpy.sum(s_by_s[fine_grained_idx,:], axis=0) for fine_grained_idx in fine_grained_idx_all], axis=0)

            s_by_s_coarse_neutral = numpy.stack([numpy.sum(s_by_s_neutral[coarse_grained_idx,:], axis=0) for coarse_grained_idx in coarse_grained_idx_all], axis=0)
            s_by_s_fine_neutral = numpy.stack([numpy.sum(s_by_s_neutral[fine_grained_idx,:], axis=0) for fine_grained_idx in fine_grained_idx_all], axis=0)


            slope_all = []
            slope_neutral_all = []
            for focal_coarse_idx, focal_coarse in enumerate(coarse_grained_list):

                # ignore coarse-grained taxa with less than five fine-grained taxa
                if len(focal_coarse) < 5:
                    continue

                fine_in_coarse_all = []
                # identify fine-grain taxa containing coarse-grained members
                f_idx_all = []
                for f_idx, f in enumerate(fine_grained_list):

                    is_fine_in_coarse = bool(set(focal_coarse) & set(f))

                    if is_fine_in_coarse == True:
                        fine_in_coarse_all.extend(f)
                        f_idx_all.append(f_idx)

                f_idx_all = numpy.asarray(f_idx_all)
                # ignore coarse-grained taxa with less than five fine-grained taxa
                if len(f_idx_all) < 5:
                    continue

                s_by_s_fine_focal = s_by_s_fine[f_idx_all,:]
                s_by_s_coarse_nonfocal = numpy.delete(s_by_s_coarse, focal_coarse_idx, axis=0)

                s_by_s_fine_focal_neutral = s_by_s_fine_neutral[f_idx_all,:]
                s_by_s_coarse_nonfocal_neutral = numpy.delete(s_by_s_coarse_neutral, focal_coarse_idx, axis=0)

                richness_fine_focal = numpy.sum(s_by_s_fine_focal>0, axis=0)
                richness_coarse_nonfocal = numpy.sum(s_by_s_coarse_nonfocal>0, axis=0)
                
                richness_fine_focal_neutral = numpy.sum(s_by_s_fine_focal_neutral>0, axis=0)
                richness_coarse_nonfocal_neutral = numpy.sum(s_by_s_coarse_nonfocal_neutral>0, axis=0)

                if len(measure_fine) < 5:
                    continue

                slope, intercept, r_value, p_value, std_err = stats.linregress(richness_coarse_nonfocal, richness_fine_focal)
                slope_neutral, intercept_neutral, r_value_neutral, p_value_neutral, std_err_neutral = stats.linregress(richness_coarse_nonfocal_neutral, richness_fine_focal_neutral)

                slope_all.append(slope)
                slope_neutral_all.append(slope_neutral)

            
            slope_all = numpy.asarray(slope_all)
            slope_neutral_all = numpy.asarray(slope_neutral_all)

            idx_to_keep = numpy.isfinite(slope_all) & numpy.isfinite(slope_neutral_all) & (numpy.absolute(slope_all)>0)

            if sum(idx_to_keep) < 3:
                continue
            
            slope_all = slope_all[idx_to_keep]
            slope_neutral_all = slope_neutral_all[idx_to_keep]

            mean_slope_all = numpy.mean(slope_all)
            mean_slope_neutral_all = numpy.mean(slope_neutral_all)

            # error
            mean_error_slope_neutral = numpy.mean(numpy.absolute( slope_neutral_all - slope_all) / numpy.absolute(slope_all))


             # predict diversity and richnesss
            observed_mean_richness =  numpy.mean(numpy.apply_along_axis(diversity_utils.calculate_richness, 0, s_by_s_coarse))
            predicted_mean_richness =  numpy.mean(numpy.apply_along_axis(diversity_utils.calculate_richness, 0, s_by_s_coarse_neutral))


            dbd_dict[environment]['phylo'][coarse_distance] = {}
            dbd_dict[environment]['phylo'][coarse_distance]['slope_all'] = slope_all.tolist()
            dbd_dict[environment]['phylo'][coarse_distance]['slope_neutral_all'] = slope_neutral_all.tolist()
            dbd_dict[environment]['phylo'][coarse_distance]['mean_slope'] = mean_slope_all
            dbd_dict[environment]['phylo'][coarse_distance]['mean_slope_neutral'] = mean_slope_neutral_all
            dbd_dict[environment]['phylo'][coarse_distance]['mean_error_slope_neutral'] = mean_error_slope_neutral

            dbd_dict[environment]['phylo'][coarse_distance]['observed_mean_richness'] = observed_mean_richness
            dbd_dict[environment]['phylo'][coarse_distance]['predicted_mean_richness'] = predicted_mean_richness



    
    sys.stderr.write("Saving diversity dictionary...\n")
    with open(richness_dbd_neutral_dict_path, 'wb') as handle:
        pickle.dump(dbd_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)



def load_richness_neutral_dbd_dict():

    with open(richness_dbd_neutral_dict_path, 'rb') as handle:
        dbd_slope_dict = pickle.load(handle)
    return dbd_slope_dict







def test_slope_plot():

    dbd_dict = load_richness_neutral_dbd_dict()

    slm_dbd_dict = dbd_utils.load_richness_slm_dbd_dict()

    environment = diversity_utils.environments_to_keep[0]

    #observed = numpy.asarray(dbd_dict[environment]['taxon']['family']['slope_all'])
    #predicted = numpy.asarray(dbd_dict[environment]['taxon']['family']['slope_slm_all'])

    observed = numpy.asarray(dbd_dict[environment]['taxon']['family']['slope_all'])
    predicted = numpy.asarray(dbd_dict[environment]['taxon']['family']['slope_slm_all'])

    #print(dbd_dict[environment]['phylo'].keys())
    error_neutral = dbd_dict[environment]['phylo'][0.27342744561652355]['mean_error_slope_neutral']
    error_slm = slm_dbd_dict[environment]['phylo'][0.27342744561652355]['mean_error_slope_slm']


    idx_to_keep = (observed>0) & (predicted > 0)
    observed = observed[idx_to_keep]
    predicted = predicted[idx_to_keep]


    fig, ax = plt.subplots(figsize=(4,4))

    ax.scatter(observed, predicted)

    merged_ = numpy.concatenate((observed, predicted),axis=0)
    min_ = min(merged_)
    max_ = max(merged_)
    ax.set_xlim([min_*0.2,max_*4]) 
    ax.set_ylim([min_*0.2,max_*4])
    ax.plot([min_*0.2,max_*4], [min_*0.2,max_*4], lw=2,ls='--',c='k',zorder=1, label='1:1')
    ax.set_xscale('log', base=10)
    ax.set_yscale('log', base=10)

    ax.set_xlabel("Observed DBD richness slope", fontsize=9)
    ax.set_ylabel("Predicted DBD richness slope, UNTB", fontsize=9)

    fig.subplots_adjust(wspace=0.3, hspace=0.3)
    fig.savefig("%stest_slope_neutral.png" % config.analysis_directory, format='png', bbox_inches = "tight", pad_inches = 0.5, dpi = 600)
    plt.close()




if __name__=='__main__':

    #make_rarefied_sads_dict()
    make_neutral_dbd_slope_dict()



